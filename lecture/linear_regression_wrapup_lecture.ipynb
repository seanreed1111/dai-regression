{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary/Review/One More Thing about regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have been doing what are known as REGRESSION models\n",
    "\n",
    "A Regression task is when you try to predict a *continuous* variable using other variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression - A Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   admit   400 non-null    int64  \n",
      " 1   gre     400 non-null    int64  \n",
      " 2   gpa     400 non-null    float64\n",
      " 3   rank    400 non-null    int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 12.6 KB\n"
     ]
    }
   ],
   "source": [
    "#Review: Linear Regression Models\n",
    "admissions = pd.read_csv(\"https://stats.idre.ucla.edu/stat/data/binary.csv\")\n",
    "admissions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.317500</td>\n",
       "      <td>587.700000</td>\n",
       "      <td>3.389900</td>\n",
       "      <td>2.48500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.466087</td>\n",
       "      <td>115.516536</td>\n",
       "      <td>0.380567</td>\n",
       "      <td>0.94446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>2.260000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>3.130000</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>580.000000</td>\n",
       "      <td>3.395000</td>\n",
       "      <td>2.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>660.000000</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>3.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            admit         gre         gpa       rank\n",
       "count  400.000000  400.000000  400.000000  400.00000\n",
       "mean     0.317500  587.700000    3.389900    2.48500\n",
       "std      0.466087  115.516536    0.380567    0.94446\n",
       "min      0.000000  220.000000    2.260000    1.00000\n",
       "25%      0.000000  520.000000    3.130000    2.00000\n",
       "50%      0.000000  580.000000    3.395000    2.00000\n",
       "75%      1.000000  660.000000    3.670000    3.00000\n",
       "max      1.000000  800.000000    4.000000    4.00000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admissions.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: Which columns are categorical and which are continuous?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "A Regression task is when you try to predict a *continuous* variable using other variables, which can be of any type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = 7,6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Split arrays or matrices into random train and test subsets\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Quick utility that wraps input validation and\u001b[0m\n",
       "\u001b[0;34m    ``next(ShuffleSplit().split(X, y))`` and application to input data\u001b[0m\n",
       "\u001b[0;34m    into a single call for splitting (and optionally subsampling) data in a\u001b[0m\n",
       "\u001b[0;34m    oneliner.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Read more in the :ref:`User Guide <cross_validation>`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Parameters\u001b[0m\n",
       "\u001b[0;34m    ----------\u001b[0m\n",
       "\u001b[0;34m    *arrays : sequence of indexables with same length / shape[0]\u001b[0m\n",
       "\u001b[0;34m        Allowed inputs are lists, numpy arrays, scipy-sparse\u001b[0m\n",
       "\u001b[0;34m        matrices or pandas dataframes.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    test_size : float or int, default=None\u001b[0m\n",
       "\u001b[0;34m        If float, should be between 0.0 and 1.0 and represent the proportion\u001b[0m\n",
       "\u001b[0;34m        of the dataset to include in the test split. If int, represents the\u001b[0m\n",
       "\u001b[0;34m        absolute number of test samples. If None, the value is set to the\u001b[0m\n",
       "\u001b[0;34m        complement of the train size. If ``train_size`` is also None, it will\u001b[0m\n",
       "\u001b[0;34m        be set to 0.25.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    train_size : float or int, default=None\u001b[0m\n",
       "\u001b[0;34m        If float, should be between 0.0 and 1.0 and represent the\u001b[0m\n",
       "\u001b[0;34m        proportion of the dataset to include in the train split. If\u001b[0m\n",
       "\u001b[0;34m        int, represents the absolute number of train samples. If None,\u001b[0m\n",
       "\u001b[0;34m        the value is automatically set to the complement of the test size.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    random_state : int or RandomState instance, default=None\u001b[0m\n",
       "\u001b[0;34m        Controls the shuffling applied to the data before applying the split.\u001b[0m\n",
       "\u001b[0;34m        Pass an int for reproducible output across multiple function calls.\u001b[0m\n",
       "\u001b[0;34m        See :term:`Glossary <random_state>`.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    shuffle : bool, default=True\u001b[0m\n",
       "\u001b[0;34m        Whether or not to shuffle the data before splitting. If shuffle=False\u001b[0m\n",
       "\u001b[0;34m        then stratify must be None.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    stratify : array-like, default=None\u001b[0m\n",
       "\u001b[0;34m        If not None, data is split in a stratified fashion, using this as\u001b[0m\n",
       "\u001b[0;34m        the class labels.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Returns\u001b[0m\n",
       "\u001b[0;34m    -------\u001b[0m\n",
       "\u001b[0;34m    splitting : list, length=2 * len(arrays)\u001b[0m\n",
       "\u001b[0;34m        List containing train-test split of inputs.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        .. versionadded:: 0.16\u001b[0m\n",
       "\u001b[0;34m            If the input is sparse, the output will be a\u001b[0m\n",
       "\u001b[0;34m            ``scipy.sparse.csr_matrix``. Else, output type is the same as the\u001b[0m\n",
       "\u001b[0;34m            input type.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Examples\u001b[0m\n",
       "\u001b[0;34m    --------\u001b[0m\n",
       "\u001b[0;34m    >>> import numpy as np\u001b[0m\n",
       "\u001b[0;34m    >>> from sklearn.model_selection import train_test_split\u001b[0m\n",
       "\u001b[0;34m    >>> X, y = np.arange(10).reshape((5, 2)), range(5)\u001b[0m\n",
       "\u001b[0;34m    >>> X\u001b[0m\n",
       "\u001b[0;34m    array([[0, 1],\u001b[0m\n",
       "\u001b[0;34m           [2, 3],\u001b[0m\n",
       "\u001b[0;34m           [4, 5],\u001b[0m\n",
       "\u001b[0;34m           [6, 7],\u001b[0m\n",
       "\u001b[0;34m           [8, 9]])\u001b[0m\n",
       "\u001b[0;34m    >>> list(y)\u001b[0m\n",
       "\u001b[0;34m    [0, 1, 2, 3, 4]\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    >>> X_train, X_test, y_train, y_test = train_test_split(\u001b[0m\n",
       "\u001b[0;34m    ...     X, y, test_size=0.33, random_state=42)\u001b[0m\n",
       "\u001b[0;34m    ...\u001b[0m\n",
       "\u001b[0;34m    >>> X_train\u001b[0m\n",
       "\u001b[0;34m    array([[4, 5],\u001b[0m\n",
       "\u001b[0;34m           [0, 1],\u001b[0m\n",
       "\u001b[0;34m           [6, 7]])\u001b[0m\n",
       "\u001b[0;34m    >>> y_train\u001b[0m\n",
       "\u001b[0;34m    [2, 0, 3]\u001b[0m\n",
       "\u001b[0;34m    >>> X_test\u001b[0m\n",
       "\u001b[0;34m    array([[2, 3],\u001b[0m\n",
       "\u001b[0;34m           [8, 9]])\u001b[0m\n",
       "\u001b[0;34m    >>> y_test\u001b[0m\n",
       "\u001b[0;34m    [1, 4]\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    >>> train_test_split(y, shuffle=False)\u001b[0m\n",
       "\u001b[0;34m    [[0, 1, 2], [3, 4]]\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mn_arrays\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At least one array required as input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtrain_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'random_state'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstratify\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stratify'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shuffle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid parameters passed: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mn_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_shuffle_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                              \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mstratify\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"Stratified train/test split is not implemented for \"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;34m\"shuffle=False\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_train\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mstratify\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mCVClass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedShuffleSplit\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mCVClass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mShuffleSplit\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCVClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                     \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                     \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_safe_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                                     \u001b[0m_safe_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/miniconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_test_split??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#version 3\n",
    "def statsmodels_train_test_split(df, stratify=None, **kwargs):\n",
    "\n",
    "    if stratify is None:\n",
    "        y, X = df.iloc[:,0], df.drop(columns=df.columns[0])\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y, **kwargs)\n",
    "    else:\n",
    "        y, X = stratify, df.drop(columns = stratify.name)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y, **kwargs)\n",
    "    \n",
    "    return pd.concat([X_train, y_train], axis=1), pd.concat([X_test, y_test], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = statsmodels_train_test_split(admissions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try to model gre score versus the other variables, e.g.,\n",
    "# gre ~ C(admit) + gpa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There is a deep connection between linear regression and the normal distribution. I'm going to mention it now, but not do anything with it yet.\n",
    "# Here it is:\n",
    "\n",
    "## When we do a linear regression of the form we wrote above, we are making the assumption that *gre* is distributed as a normal random variable!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "620    30\n",
       "580    29\n",
       "540    27\n",
       "800    25\n",
       "520    24\n",
       "560    24\n",
       "660    24\n",
       "600    23\n",
       "700    22\n",
       "640    21\n",
       "500    21\n",
       "680    20\n",
       "480    16\n",
       "460    14\n",
       "720    11\n",
       "400    11\n",
       "740    11\n",
       "440    10\n",
       "380     8\n",
       "420     7\n",
       "780     5\n",
       "760     5\n",
       "340     4\n",
       "360     4\n",
       "300     3\n",
       "220     1\n",
       "Name: gre, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the value counts of gre in this dataset?\n",
    "\n",
    "admissions['gre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1dfac490>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(admissions['gre'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's treat gre as continuous and normally distributed for now, though this is debatable!\n",
    "### Also notice that all gre scores are greater than zero. This would usually be bad, since normal distributions centered at zero allow both positive and negative values with equal probability\n",
    "\n",
    "### Since values of gre are generally not near zero and look vaguely normally distributed, we'll push forward with this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>gre</td>       <th>  R-squared:         </th> <td>   0.169</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.163</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   30.11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 08 Sep 2020</td> <th>  Prob (F-statistic):</th> <td>1.24e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:38:28</td>     <th>  Log-Likelihood:    </th> <td> -1817.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   300</td>      <th>  AIC:               </th> <td>   3642.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   297</td>      <th>  BIC:               </th> <td>   3653.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>     <td>  216.2298</td> <td>   53.231</td> <td>    4.062</td> <td> 0.000</td> <td>  111.472</td> <td>  320.988</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(admit)[T.1]</th> <td>   37.8320</td> <td>   13.248</td> <td>    2.856</td> <td> 0.005</td> <td>   11.760</td> <td>   63.904</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gpa</th>           <td>  105.2610</td> <td>   15.806</td> <td>    6.659</td> <td> 0.000</td> <td>   74.155</td> <td>  136.367</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.155</td> <th>  Durbin-Watson:     </th> <td>   2.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.925</td> <th>  Jarque-Bera (JB):  </th> <td>   0.264</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.040</td> <th>  Prob(JB):          </th> <td>   0.876</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.878</td> <th>  Cond. No.          </th> <td>    32.8</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    gre   R-squared:                       0.169\n",
       "Model:                            OLS   Adj. R-squared:                  0.163\n",
       "Method:                 Least Squares   F-statistic:                     30.11\n",
       "Date:                Tue, 08 Sep 2020   Prob (F-statistic):           1.24e-12\n",
       "Time:                        20:38:28   Log-Likelihood:                -1817.8\n",
       "No. Observations:                 300   AIC:                             3642.\n",
       "Df Residuals:                     297   BIC:                             3653.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================\n",
       "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "Intercept       216.2298     53.231      4.062      0.000     111.472     320.988\n",
       "C(admit)[T.1]    37.8320     13.248      2.856      0.005      11.760      63.904\n",
       "gpa             105.2610     15.806      6.659      0.000      74.155     136.367\n",
       "==============================================================================\n",
       "Omnibus:                        0.155   Durbin-Watson:                   2.025\n",
       "Prob(Omnibus):                  0.925   Jarque-Bera (JB):                0.264\n",
       "Skew:                          -0.040   Prob(JB):                        0.876\n",
       "Kurtosis:                       2.878   Cond. No.                         32.8\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula = 'gre ~ C(admit) + gpa'\n",
    "lm = smf.ols(formula=formula, data=train).fit()\n",
    "lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210    567.801554\n",
       "120    647.738004\n",
       "299    574.117216\n",
       "358    642.474954\n",
       "398    600.432470\n",
       "          ...    \n",
       "313    638.264513\n",
       "316    569.844851\n",
       "42     585.634004\n",
       "369    625.695115\n",
       "141    624.580580\n",
       "Length: 100, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = lm.predict(test)\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion of R_squared and Adjusted R_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12239433217408768"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(test['gre'], y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12548.88344424272"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(test['gre'], y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I make a different model, my r-squared and mean_squared_error will be different\n",
    "In general, if I add a variable I would expect my r-squared to go up.\n",
    "\n",
    "**Adjusted R-Squared** is generally considered SUPERIOR to R-Squared, because it adjusts for the fact that you've added more variables, so only go up when you add a new variable AND the fit is a better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>gre</td>       <th>  R-squared:         </th> <td>   0.186</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   13.40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 08 Sep 2020</td> <th>  Prob (F-statistic):</th> <td>8.82e-12</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:39:06</td>     <th>  Log-Likelihood:    </th> <td> -1814.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   300</td>      <th>  AIC:               </th> <td>   3641.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   294</td>      <th>  BIC:               </th> <td>   3664.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>     <td>  209.8145</td> <td>   56.264</td> <td>    3.729</td> <td> 0.000</td> <td>   99.084</td> <td>  320.545</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(admit)[T.1]</th> <td>   33.1256</td> <td>   13.708</td> <td>    2.417</td> <td> 0.016</td> <td>    6.148</td> <td>   60.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(rank)[T.2]</th>  <td>   13.3080</td> <td>   17.965</td> <td>    0.741</td> <td> 0.459</td> <td>  -22.048</td> <td>   48.664</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(rank)[T.3]</th>  <td>  -23.0318</td> <td>   18.914</td> <td>   -1.218</td> <td> 0.224</td> <td>  -60.255</td> <td>   14.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(rank)[T.4]</th>  <td>   -4.9769</td> <td>   22.249</td> <td>   -0.224</td> <td> 0.823</td> <td>  -48.764</td> <td>   38.810</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gpa</th>           <td>  108.3309</td> <td>   15.847</td> <td>    6.836</td> <td> 0.000</td> <td>   77.144</td> <td>  139.518</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.763</td> <th>  Durbin-Watson:     </th> <td>   2.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.683</td> <th>  Jarque-Bera (JB):  </th> <td>   0.850</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.041</td> <th>  Prob(JB):          </th> <td>   0.654</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.752</td> <th>  Cond. No.          </th> <td>    35.6</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    gre   R-squared:                       0.186\n",
       "Model:                            OLS   Adj. R-squared:                  0.172\n",
       "Method:                 Least Squares   F-statistic:                     13.40\n",
       "Date:                Tue, 08 Sep 2020   Prob (F-statistic):           8.82e-12\n",
       "Time:                        20:39:06   Log-Likelihood:                -1814.7\n",
       "No. Observations:                 300   AIC:                             3641.\n",
       "Df Residuals:                     294   BIC:                             3664.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================\n",
       "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------\n",
       "Intercept       209.8145     56.264      3.729      0.000      99.084     320.545\n",
       "C(admit)[T.1]    33.1256     13.708      2.417      0.016       6.148      60.104\n",
       "C(rank)[T.2]     13.3080     17.965      0.741      0.459     -22.048      48.664\n",
       "C(rank)[T.3]    -23.0318     18.914     -1.218      0.224     -60.255      14.192\n",
       "C(rank)[T.4]     -4.9769     22.249     -0.224      0.823     -48.764      38.810\n",
       "gpa             108.3309     15.847      6.836      0.000      77.144     139.518\n",
       "==============================================================================\n",
       "Omnibus:                        0.763   Durbin-Watson:                   2.010\n",
       "Prob(Omnibus):                  0.683   Jarque-Bera (JB):                0.850\n",
       "Skew:                          -0.041   Prob(JB):                        0.654\n",
       "Kurtosis:                       2.752   Cond. No.                         35.6\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formula = 'gre ~ C(admit) + gpa + C(rank)' # adds rank as a categorical variable\n",
    "lm2 = smf.ols(formula=formula, data=train).fit()\n",
    "lm2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we see that both R-Squared and Adjusted R-squared went up on the TRAINING data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10453063162492138"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's check the test data\n",
    "y_test_pred = lm2.predict(test)\n",
    "\n",
    "r2_score(test['gre'], y_test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so, r2_score went up. Adjusted r-squared went up as well, but not as much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
