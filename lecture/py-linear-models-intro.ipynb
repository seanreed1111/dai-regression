{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display, Image\n",
    "\n",
    "SMALL_SIZE = 15\n",
    "MEDIUM_SIZE = 16\n",
    "LARGE_SIZE = 18\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=LARGE_SIZE)   # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"../images/galvanize-logo.png\" alt=\"galvanize-logo\" align=\"center\" style=\"width: 256px;\"/>\n",
    "</center>\n",
    "\n",
    "<hr />\n",
    "\n",
    "\n",
    "## Python Linear Models Intro\n",
    "\n",
    "An introduction to using linear machine learning models in Python to make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"../images/python-logo.png\" alt=\"python-logo\" align=\"center\" style=\"width: 256px;\"/>\n",
    "</center>\n",
    "\n",
    "<hr />\n",
    "\n",
    "### Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. **Create a Model** - Use sklearn's implementation to create and train a simple linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "2. **Coefficients** - Interpret coefficients of Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "3. **Model Validation** - Validate Linear Regression Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Read the objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Introduction\n",
    "\n",
    "In this lesson, we will explore the use of machine learning models to predict a \"target\" (also called a dependent variable or a response variable) from one or more data \"features\" (also called independent variables or predictor variables)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Introducing \"Linear Regression\"\n",
    "\n",
    "Here we will focus on a model called \"Linear Regression\".\n",
    "\n",
    "The name is descriptive, in that to use it we need to assume that the relationship of the target to the features is linear. And \"regression\" means the target is a numeric value.\n",
    "\n",
    "Linear Regression is an example of supervised learning, since we can train the model with data in which the targets (also called \"labels\") are known."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Models\n",
    "\n",
    "* A machine learning model can predict as-yet unknown information\n",
    "* A supervised learning model uses known information to \"learn\" how to predict\n",
    "* This is powerful, as we can \"see into the future\"\n",
    "* A business may save a lot of money if it can predict in this way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How do models work?\n",
    "\n",
    "* Models use algorithms to process data\n",
    "* When a model is given known data, it adjusts its internal settings\n",
    "* These are known as \"parameters\"\n",
    "* Later, that model can make predictions about new, unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dependent and independent variables\n",
    "\n",
    "* The information we want to predict is called the \"target\"\n",
    "* The target depends on independent variables called \"features\"\n",
    "\n",
    "Note that there can be many features that contribute to predicting a target.\n",
    "\n",
    "We depend on there being a \"relationship\" between the features and the target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What is a linear relationship?\n",
    "\n",
    "In this lesson, we are looking at special relationships between features and a target.\n",
    "\n",
    "These relationships are assumed to be \"linear\" - what does this mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Graphing a linear relationship\n",
    "\n",
    "Perhaps the simplest way to understand a linear relationship is to use a graph:\n",
    "\n",
    "<center>\n",
    "<img src=\"../images/simple_lr_graph_perfect.png\" alt=\"simple_lr_graph_perfect\" align=\"center\" style=\"width: 256px;\"/>\n",
    "</center>\n",
    "\n",
    "Let's call the X axis a feature and the Y axis the target. In a perfect linear relationship, all data points lie exactly on a straight line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Real-world linear relationships\n",
    "\n",
    "But real-world data is not perfect. Here is what real data might look like\n",
    "\n",
    "<center>\n",
    "<img src=\"../images/simple_lr_graph.png\" alt=\"simple_lr_graph\" align=\"center\" style=\"width: 256px;\"/>\n",
    "</center>\n",
    "\n",
    "Is this still linear?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Yes! We can still treat this data as linear.\n",
    "\n",
    "There is clearly a linear trend there, even if not perfect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Linear Regression in action\n",
    "\n",
    "Since real-world data does not supply perfect linear relationships, the job of the model is to find a line that is the \"best fit\".\n",
    "\n",
    "<center>\n",
    "<img src=\"../images/simple_lr_graph_fit.png\" alt=\"simple_lr_graph_fit\" align=\"center\" style=\"width: 256px;\"/>\n",
    "</center>\n",
    " \n",
    "Note that the distance from each point to the line is indicated by the small vertical lines. These show how the real data differs from its linear model. These differences are called \"residuals\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Consider asking the class, \"Do predictions always lie on this line?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A concrete example\n",
    "\n",
    "Let's look at a simple example - height vs. shoe size:\n",
    "\n",
    "<center>\n",
    "<img src=\"../images/simple_lr_graph_shoe_size.png\" alt=\"simple_lr_graph_shoe_size\" align=\"center\" style=\"width: 256px;\"/>\n",
    "</center>\n",
    "\n",
    "This is \"linear enough\" to be valuable and will produce pretty good predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A non-linear example\n",
    "\n",
    "Now let's look at an example of orbital speed vs. distance to the Sun:\n",
    "\n",
    "<center>\n",
    "<img src=\"../images/simple_lr_graph_orbital_speed.png\" alt=\"simple_lr_graph_orbital_speed\" align=\"center\" style=\"width: 256px;\"/>\n",
    "</center>\n",
    "\n",
    "This is clearly not linear. Without doing more processing to your data, this example would produce poor results in a linear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Go to https://phet.colorado.edu/sims/html/least-squares-regression/latest/least-squares-regression_en.html to demonstrate the idea interactively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Checks for Understanding\n",
    "\n",
    "1. How does a simple Linear Regression model learn from training data?\n",
    "\n",
    "\n",
    "2. What is the difference between a target and a feature?\n",
    "\n",
    "\n",
    "3. What constitutes a \"linear relationship\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using the equation of a line for prediction\n",
    "\n",
    "The equation of a line, which is enough for simple Linear Regression, is:\n",
    "\n",
    "$y = mx + b$\n",
    "\n",
    "This can also be written:\n",
    "\n",
    "$\\hat{y}_i = \\beta_0 + \\beta_1 x$\n",
    "\n",
    "Here, $\\hat{y}_i$ is the predicted output of the model for each sample, $i$.\n",
    "The betas are the \"beta coefficients\" of the model.\n",
    "\n",
    "But we typically have more than one $x$, which makes things more interesting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Multiple Linear Regression\n",
    "\n",
    "So far, we have been working with just one feature.\n",
    "\n",
    "Linear Regression can deal with any number of features!\n",
    "\n",
    "With each additional feature, we add a new dimension to the graph, so things quickly become hard to visualize...\n",
    "\n",
    "For example, with one feature, we can show the results on a two dimensional graph, like above.\n",
    "\n",
    "With two features, the line becomes a plane in 3D space.\n",
    "\n",
    "Beyond that, the math still works, but there are too many dimensions to imagine easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using the Beta Coefficients\n",
    "\n",
    "Let's look at the formula for predicting a target using more than one feature:\n",
    "\n",
    "$\\hat{y}_i = \\beta_0 + \\beta_1 x1_i + \\ldots + \\beta_p xp_i$\n",
    "\n",
    "To calculate a prediction, we find the sum of the constant ($\\beta_0$) and all of the feature values scaled by their coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Interpretting the Beta Coefficients\n",
    "\n",
    "Linear Regression has the nice property that you can *see* how it works - the effect of the coefficients on predictions is fairly easy to comprehend.\n",
    "\n",
    "Just from looking at the coefficients, we can see how much change happens in the target given a change in a feature. Put another way, each beta coefficient is the mean change in the response variable (target) per unit change in its predictor variable (feature)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Checks for Understanding\n",
    "\n",
    "1. What is the role of the beta coefficients?\n",
    "\n",
    "\n",
    "2. What graphical shape does each beta coefficient (plus the constant coefficient) represent?\n",
    "\n",
    "\n",
    "3. How are the beta coefficients used for prediction of unknown targets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### An actual example\n",
    "\n",
    "Let's take a look at doing a real Linear Regression. First, we need to import a few Python modules..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we read the data and take a look at a bit of it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df_full = pd.read_csv('data/cars.csv')\n",
    "df_full.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Our target is miles per gallon (mpg), and we decide we only want to use 3 features. Here, we make a new dataframe with only the columns we need. In Linear Regresion, it is not always better to include more (or all!) of the features..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df = df_full[['mpg', 'cylinders', 'displacement', 'weight']]\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's take another look at our new dataframe..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df.describe().T[['min', 'max']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Remember that Linear Regression assumes the data is linear. One way to tell is to graph the data and take a look..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df, palette='husl', corner=True, diag_kind='kde', kind='reg', markers='+', \n",
    "                 plot_kws={'line_kws':{'color':'red', 'alpha':0.5}}, height=1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Also, we need to avoid choosing features that depend on each other (multi-colinearity) and give no new information. A heat map can help here...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr(), annot=True, fmt='0.2f', cmap='Purples');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Remember that our target (y) is miles per gallon. Let's separate out this from our features (X)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "y = df.mpg\n",
    "X = df[['cylinders', 'displacement', 'weight']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Time to train our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# training\n",
    "model = LinearRegression().fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "After training, we can ask the model for its parameters (beta coefficients)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# model parameters\n",
    "model.intercept_, model.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Since we have the actual target values (y), we can compare them to the model's predictions (y_hat), which enables us to see how good the model is. First, get the predictions and visually compare them to the actuals..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# comparing y to y_hat\n",
    "y_hat = model.predict(X)\n",
    "list(zip(y, y_hat))[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "One way to calculate how well the model predicts is to calcuate the \"r squared\" score. A function is available to calculate this metric for you. 1.0 is the best score possible..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# R-squared\n",
    "r2_score(y, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If you want a metric that is in the same units as the predictions (and is more easily interpretable as a goodness-of-fit measure), try the RMSE..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# mean squared error\n",
    "mean_squared_error(y, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# root mean squared error\n",
    "mean_squared_error(y, y_hat) ** 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can also look at the residuals directly by subtracing the predictions from the actual values..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "residuals = (y - y_hat).values[:20]\n",
    "residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's visualize this better by making a cool plot based on the targets and one of the features..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# visualize mpg vs weight, fitted line, and residuals\n",
    "xs = np.linspace(1500, 5200)\n",
    "b0 = model.intercept_\n",
    "b1 = model.coef_[-1]\n",
    "ys = b0 + (b1 * xs)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.scatter(X.weight, y, c='#ff33cc', alpha=0.7)\n",
    "plt.plot(xs, ys, label='y=mx+b')\n",
    "for x_i, y_i in zip(X.weight, y):\n",
    "    plt.plot([x_i, x_i], [y_i, b1*x_i+b0], color='gray', linestyle='dashed', alpha=0.3)\n",
    "plt.xlabel('weight')\n",
    "plt.ylabel('mpg')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Checks for Understanding\n",
    "\n",
    "1. What are the main two parameters of the `fit` method on a `LinearRegression`?\n",
    "\n",
    "\n",
    "2. What are some of the ways we can evaluate our model's ability to predict well?\n",
    "\n",
    "\n",
    "3. What is the purpose of the \"heatmap\" plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Break-out Exercise\n",
    "\n",
    "Create your own data to be used in a simple Linear Regression model. Since it is \"simple\", you will have a single list of feature values and a single list of targets.\n",
    "\n",
    "Instantiate a `LinearRegression` object and call its `fit` method. Then generate predictions using its `predict` method. Are the predictions what you expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "rise": {
   "autolaunch": true,
   "enable_chalkboard": true,
   "footer": "<h3>Galvanize, Inc</h3>",
   "start_slideshow_at": "beginning",
   "theme": "sky",
   "transition": "slide"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
